{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawl_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdYR/CMME0PHL56oCxJZ0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrieuLe0801/craw_data_fedex/blob/master/crawl_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bDubqqgaVKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78670c3a-b3c2-422a-f8e8-951c56c690f7"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install pandas\n",
        "!pip install joblib\n",
        "!pip install bs4\n",
        "!pip install fake_useragent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,149 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,715 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [878 kB]\n",
            "Fetched 5,014 kB in 5s (934 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 81.0 MB of archives.\n",
            "After this operation, 273 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 87.0.4280.66-0ubuntu0.18.04.1 [1,122 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 87.0.4280.66-0ubuntu0.18.04.1 [71.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 87.0.4280.66-0ubuntu0.18.04.1 [3,716 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 87.0.4280.66-0ubuntu0.18.04.1 [4,488 kB]\n",
            "Fetched 81.0 MB in 9s (9,027 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 146374 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_87.0.4280.66-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Collecting fake_useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Building wheels for collected packages: fake-useragent\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp36-none-any.whl size=13485 sha256=2b17d4be874eba5685ccc1956b2b9e683f21cd42ddeb487c5397d1e8a19629f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "Successfully built fake-useragent\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-0.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ4GJ2TG3KnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47c9b45-32f7-4d7d-c4ad-055567909869"
      },
      "source": [
        "from selenium import webdriver\n",
        "import time\n",
        "import selenium.common.exceptions as exception\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import threading\n",
        "import itertools\n",
        "import concurrent\n",
        "from joblib import Parallel, delayed, parallel_backend\n",
        "from queue import Queue\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# threads= mp.cpu_count()\n",
        "pool = mp.Pool(4)\n",
        "q_task = Queue\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "# from pyvirtualdisplay import Display \n",
        "deliver_country=['United States','United Kingdom', 'France', 'Germany', 'Italy']\n",
        "global dataframe \n",
        "dataframe = pd.DataFrame(columns=[\"Country_from\",\"Country_to\",\"Status\",\"Shipment_number\",\"Delivery\"])\n",
        "global result\n",
        "result = []\n",
        "global backup\n",
        "backup = mp.Manager().list()\n",
        "global list_pages\n",
        "list_pages = mp.Manager().list()\n",
        "lock = threading.RLock()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REuwrF7DfNQs"
      },
      "source": [
        "# chrome driver\n",
        "def chrome_driver():\n",
        "  options = webdriver.ChromeOptions()\n",
        "  options.add_argument('--ignore-certificate-errors')\n",
        "  options.add_argument('--headless')\n",
        "  options.add_argument('--no-sandbox')\n",
        "  options.add_argument('--disable-dev-shm-usage')\n",
        "  options.add_argument('--incognito')\n",
        "  options.add_argument(\"--disable-gpu\")\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)\n",
        "  driver.maximize_window\n",
        "  return driver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr4kswmdWjcU"
      },
      "source": [
        "def save_csv(list_data,name):\n",
        "  dataframe = pd.DataFrame(columns=[\"Country_from\",\"Country_to\",\"Status\",\"Shipment_number\",\"Delivery\"])\n",
        "  dataframe = pd.DataFrame(list_data, columns=dataframe.columns)\n",
        "  print(dataframe)\n",
        "  dataframe.to_csv('drive/My Drive/Colab Notebooks/fedex_data/{}.csv'.format(name), index=False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxXmmCL0HJy4"
      },
      "source": [
        "# def spliter(x):\n",
        "#   return x.text.split(\"\\n\")\n",
        "\n",
        "def filter(i,sub_list):\n",
        "  item = i.text.split(\"\\n\")\n",
        "  country_attribute = item[2].strip()\n",
        "  if country_attribute.find(\",\") == -1:\n",
        "    if country_attribute in deliever_country:\n",
        "      if item.index(\"Shipment number\") == 7:\n",
        "        sub_list.append([item[0],item[2],item[4] +\" \"+item[5]+\" \"+ item[6],item[8],item[10],item[12]])\n",
        "      else:\n",
        "        sub_list.append([item[0],item[2],item[4],item[6],item[8],item[10]])\n",
        "    else:\n",
        "      pass\n",
        "  else:\n",
        "    if country_attribute.split(\",\")[1].strip() in deliever_country:\n",
        "      if item.index(\"Shipment number\") == 7:\n",
        "        sub_list.append([item[0],item[2],item[4] +\" \"+item[5]+\" \"+ item[6],item[8],item[10],item[12]])\n",
        "      else:\n",
        "        sub_list.append([item[0],item[2],item[4],item[6],item[8],item[10]])\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "def filter_item(list_item):\n",
        "  sub_list = []\n",
        "  # pool.starmap(filter,[[i,sub_list] for i in list_item])\n",
        "  # pool.close()\n",
        "  for item in list_item:\n",
        "    # item = i.text.split(\"\\n\")\n",
        "    country_attribute = item[2].strip()\n",
        "    if country_attribute.find(\",\") == -1:\n",
        "      if country_attribute in deliever_country:\n",
        "        if item.index(\"Shipment number\") == 7:\n",
        "          sub_list.append([item[0],item[2],item[4] +\" \"+item[5]+\" \"+ item[6],item[8],item[10],item[12]])\n",
        "        else:\n",
        "          sub_list.append([item[0],item[2],item[4],item[6],item[8],item[10]])\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "      if country_attribute.split(\",\")[1].strip() in deliever_country:\n",
        "        if item.index(\"Shipment number\") == 7:\n",
        "          sub_list.append([item[0],item[2],item[4] +\" \"+item[5]+\" \"+ item[6],item[8],item[10],item[12]])\n",
        "        else:\n",
        "          sub_list.append([item[0],item[2],item[4],item[6],item[8],item[10]])\n",
        "      else:\n",
        "        continue\n",
        "  return sub_list\n",
        "\n",
        "# accept directly to list of item customer references\n",
        "def crawl_data(customer_reference, driver_dict):\n",
        "  list_item = []\n",
        "  list_result = []\n",
        "  driver = chrome_driver()\n",
        "  try:\n",
        "    driver.get('https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}'.format(customer_reference+1))\n",
        "    driver_dict[customer_reference] = driver\n",
        "    print('Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}'.format(customer_reference+1))\n",
        "  except exception.InvalidSessionIdException:\n",
        "    print(\"Cannot load this page\")\n",
        "    return list_result\n",
        "  time.sleep(2)\n",
        "  with lock:\n",
        "    try:\n",
        "      new_driver = driver_dict.get(customer_reference)\n",
        "      accept_cookies = new_driver.find_element_by_xpath('//button[@class=\"cc-button cc-button--acceptAll\"]')\n",
        "      accept_cookies.click()\n",
        "      print('Clicked accept all cookies')\n",
        "    except NoSuchElementException:\n",
        "      print(\"No need to click accept cookie button\")\n",
        "\n",
        "    # wait items appear (300 items)\n",
        "    try:\n",
        "      WebDriverWait(new_driver, 10).until(EC.presence_of_element_located((By.XPATH, '//h2[@class=\"__c-heading __c-heading--h2 __u-mb--none\"]')))\n",
        "      # print(new_driver.find_element_by_xpath('//h2[@class=\"__c-heading __c-heading--h2 __u-mb--none\"]').text)\n",
        "      # new_driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "      # time.sleep(2)\n",
        "      # st = datetime.now()\n",
        "      list_item = [item.text.split(\"\\n\") for item in new_driver.find_elements_by_xpath(\"//*[@class='__u-mb--xl']\")]\n",
        "      if len(list_item) > 0:\n",
        "        print(\"Number of items in ref {}: {}\".format(customer_reference+1,len(list_item)))\n",
        "        list_result = filter_item(list_item)\n",
        "        print(\"size of result of ref {}: {}\".format(customer_reference+1,len(list_result)))\n",
        "      else:\n",
        "        print(\"Cannot load this ref {}\".format(customer_reference + 1))\n",
        "    except TimeoutException:\n",
        "      print(\"Time out, cannot load this page {}\".format(customer_reference))\n",
        "    driver.quit()\n",
        "  return list_result\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25uLoLTunSJ"
      },
      "source": [
        "def crawl_data_bs4(cus_ref, driver_dict):\n",
        "  list_item = []\n",
        "  driver = chrome_driver()\n",
        "  global save_time\n",
        "  global pause_time\n",
        "  try:\n",
        "    driver.get('https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}'.format(cus_ref+1))\n",
        "    driver_dict[cus_ref] = driver\n",
        "    print('Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}'.format(cus_ref+1))\n",
        "  except exception.InvalidSessionIdException:\n",
        "    print(\"Cannot load this page\")\n",
        "    return list_item\n",
        "  with lock:\n",
        "    # Click cookies accepts\n",
        "    try:\n",
        "      new_driver = driver_dict.get(cus_ref)\n",
        "      accept_cookies = new_driver.find_element_by_xpath('//button[@class=\"cc-button cc-button--acceptAll\"]')\n",
        "      accept_cookies.click()\n",
        "      print('Clicked accept all cookies')\n",
        "    except NoSuchElementException:\n",
        "      print(\"No need to click accept cookie button\")\n",
        "\n",
        "    # load beautifulsoup\n",
        "    try:\n",
        "      WebDriverWait(new_driver, 10).until(EC.presence_of_element_located((By.XPATH, '//h2[@class=\"__c-heading __c-heading--h2 __u-mb--none\"]')))\n",
        "      html = new_driver.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      new_driver.quit()\n",
        "      list_item = [[item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[0].text.replace(\"\\n\",'').strip().replace(\" \",\"\"),\n",
        "                          item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip().replace(\" \",\"\"),\n",
        "                          item.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip(),\n",
        "                          item.find('div', class_='__c-shipment__reference-content').text.split('  ')[1],\n",
        "                          item.find('span', class_='__u-hide--small-medium').text\n",
        "                          ]\n",
        "                    if item.find('span', class_='__u-hide--small-medium') != None\n",
        "                    else [item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[0].text.replace(\"\\n\",'').strip().replace(\" \",\"\"),\n",
        "                        item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip().replace(\" \",\"\"),\n",
        "                        item.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip(),\n",
        "                        item.find('div', class_='__c-shipment__reference-content').text.split('  ')[1],\n",
        "                        \" \"\n",
        "                        ]\n",
        "                    for item in\\\n",
        "                    list(filter(lambda item: item.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip() != \"Delivered\"\n",
        "                    and any([item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip() in deliver_country,\n",
        "                             item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace('\\n','').strip().find(\",\") != -1 and\n",
        "                             item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace('\\n','').strip().split(',')[1].strip() in deliver_country]),\n",
        "                        soup.find_all('div',class_='__c-shipment')))\n",
        "                  ]\n",
        "      list_pages.remove(cus_ref)\n",
        "      [backup.append(i) for i in list_item if i not in backup]\n",
        "    except TimeoutException:\n",
        "      print(\"Time out, cannot load this page {}\".format(cus_ref+1))\n",
        "      new_driver.quit()\n",
        "    print(\"Size of items list of {}: {}\".format(cus_ref+1,len(list_item)))\n",
        "    timing = datetime.now()\n",
        "    print(\"Timing:{}\".format(timing - start))\n",
        "  if (timing-save_time).total_seconds() >= 900:\n",
        "    save_time = datetime.now()\n",
        "    file_name = \"fedex_data_backup\"\n",
        "    backup_list = [i for i in backup]\n",
        "    save_csv(backup_list,file_name)\n",
        "    print(\"Save csv to drive at {}\".format(datetime.now()))\n",
        "  pause_timing = datetime.now()\n",
        "  if (pause_timing - pause_time).total_seconds() >= 1200:\n",
        "    print(\"Wait 15 minutes to free space...\")\n",
        "    time.sleep(900)\n",
        "    pause_time = datetime.now()\n",
        "  return list_item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-Zjy4FmOew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "56a6a4e6-f3ac-46f3-f4b3-b2bc06c5913e"
      },
      "source": [
        "def main(from_page, to_page):\n",
        "  data = []\n",
        "  global start\n",
        "  start = datetime.now()\n",
        "  global save_time\n",
        "  save_time = start\n",
        "  global pause_time\n",
        "  pause_time = start\n",
        "  # pause_time = start\n",
        "  print(\"start at {}\".format(start))\n",
        "  list_pages.extend(range(from_page,to_page))\n",
        "  while len(list_pages) != 0:\n",
        "    [data.append(i) for i in list(itertools.chain.from_iterable(Parallel(n_jobs=5, backend='multiprocessing')(delayed(crawl_data_bs4)(j,{}) for j in list_pages)))\n",
        "     if i not in data]\n",
        "  print(\"Finish crawl at {}, after {}\".format(datetime.now(),datetime.now()-start))\n",
        "  return data\n",
        "sub_list = []\n",
        "sub_list = main(0,5)\n",
        "result = sub_list\n",
        "save_csv(result, \"fedex_data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start at 2020-11-18 09:13:12.109611\n",
            "Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons=1\n",
            "Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons=3\n",
            "Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons=4\n",
            "Clicked accept all cookies\n",
            "Clicked accept all cookies\n",
            "Clicked accept all cookies\n",
            "Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons=2\n",
            "Clicked accept all cookies\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-df0d74294028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msub_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msub_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msave_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fedex_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-df0d74294028>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(from_page, to_page)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mlist_pages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_page\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_pages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     [data.append(i) for i in list(itertools.chain.from_iterable(Parallel(n_jobs=5, backend='multiprocessing')(delayed(crawl_data_bs4)(j,{}) for j in list_pages)))\n\u001b[0m\u001b[1;32m     14\u001b[0m      if i not in data]\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finish crawl at {}, after {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzyxD2TraDMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686fd6a9-54b2-4086-8f4e-60c92f60164f"
      },
      "source": [
        "result = sub_list\n",
        "new_result = []\n",
        "[new_result.append(i) for i in result if i not in new_result]\n",
        "# save_csv(result, \"fedex_data_{}\".format(datetime.now()))\n",
        "print(len(result))\n",
        "# for i in result:\n",
        "#   if i not in new_result:\n",
        "#     new_result.append(i)\n",
        "print(len(new_result))\n",
        "dataframe = pd.DataFrame(new_result,columns=dataframe.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1216\n",
            "1056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_25_4k1T71M_"
      },
      "source": [
        "driver_dict = {}\n",
        "start = datetime.now()\n",
        "with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
        "    futures = [executor.submit(crawl_data, i, {}) for i in range(100)]\n",
        "\n",
        "for future in concurrent.futures.as_completed(futures):\n",
        "    raw_record.extend(future.result())\n",
        "    print(len(raw_record))\n",
        "print(\"Finish crawl at {}, after {}\".format(datetime.now(),datetime.now()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Q92kkGYnZgUg",
        "outputId": "94e38d03-506f-4d7d-d8d8-5bb9fabb0b75"
      },
      "source": [
        "import argparse\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import selenium.common.exceptions as exception\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import threading\n",
        "import itertools\n",
        "import concurrent\n",
        "from joblib import Parallel, delayed, parallel_backend\n",
        "from queue import Queue\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from fake_useragent import UserAgent\n",
        "sys.path.insert(0,'chromedriver')\n",
        "deliver_country=['United States','United Kingdom', 'France', 'Germany', 'Italy']\n",
        "dataframe = pd.DataFrame(columns=[\"Country_from\",\"Country_to\",\"Status\",\"Shipment_number\",\"Delivery\"])\n",
        "lock = threading.RLock()\n",
        "start = None\n",
        "save_time = None\n",
        "pause_time = None\n",
        "\n",
        "def updateSaveTime():\n",
        "\tglobal save_time\n",
        "\tsave_time = datetime.now()\n",
        "\n",
        "def updatePauseTime():\n",
        "\tglobal pause_time\n",
        "\tpause_time = datetime.now()\n",
        "\n",
        "# chrome driver\n",
        "def chrome_driver():\n",
        "\toptions = webdriver.ChromeOptions()\n",
        "\toptions.add_argument('--user-agent={}'.format(UserAgent().random))\n",
        "\toptions.add_experimental_option(\"excludeSwitches\",[\"ignore-certificate-errors\"])\n",
        "\toptions.add_argument('--proxy-server={}'.format(\"https://179.48.251.236:32\"))\n",
        "\toptions.add_argument('ignore-certificate-errors')\n",
        "\t# options.add_argument('headless')\n",
        "\toptions.add_argument('no-sandbox')\n",
        "\toptions.add_argument('disable-dev-shm-usage')\n",
        "\toptions.add_argument('incognito')\n",
        "\toptions.add_argument('disable-gpu')\n",
        "\toptions.add_argument('allow-insecure-localhost')\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)\n",
        "\tdriver.maximize_window\n",
        "\treturn driver\n",
        "\n",
        "def save_csv(list_data,name):\n",
        "\tdataframe = pd.DataFrame(columns=[\"Country_from\",\"Country_to\",\"Status\",\"Shipment_number\",\"Delivery\"])\n",
        "\tdataframe = pd.DataFrame(list_data, columns=dataframe.columns)\n",
        "\tprint(dataframe)\n",
        "\tdataframe.to_csv('{}.csv'.format(name), index=False,header=True)\n",
        "\n",
        "def login_petco():\n",
        "  driver = chrome_driver()\n",
        "  driver.implicitly_wait(60)\n",
        "\n",
        "def crawl_data_bs4(cus_ref, driver_dict,list_pages,backup,start,list_time_control):\n",
        "\tlist_item = []\n",
        "\tdriver = chrome_driver()\n",
        "\tdriver.implicitly_wait(60)\n",
        "\ttry:\n",
        "\t\ttry:\n",
        "\t\t\tdriver.get('https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}'.format(cus_ref+1))\n",
        "\t\t\tdriver_dict[cus_ref] = driver\n",
        "\t\t\tprint(\"Loading: https://www.tnt.com/express/en_gb/site/shipping-tools/tracking.html?searchType=ref&cons={}\".format(cus_ref+1))\n",
        "\t\texcept exception.WebDriverException:\n",
        "\t\t\tprint(\"Time out, cannot load this page\")\n",
        "\t\t\tdriver.close()\n",
        "\t\t\tdriver.quit()\n",
        "\t\t\treturn list_item\n",
        "\texcept exception.InvalidSessionIdException:\n",
        "\t\tprint(\"cannot load this page\")\n",
        "\t\tdriver.close()\n",
        "\t\tdriver.quit()\n",
        "\t\treturn list_item\n",
        "\twith lock:\n",
        "\t# Click cookies accepts\n",
        "\t\ttry:\n",
        "\t\t\tnew_driver = driver_dict.get(cus_ref)\n",
        "\t\t\taccept_cookies = new_driver.find_element_by_xpath('//button[@class=\"cc-button cc-button--acceptAll\"]')\n",
        "\t\t\taccept_cookies.click()\n",
        "\t\t\tprint('Clicked accept all cookies')\n",
        "\t\texcept NoSuchElementException:\n",
        "\t\t\tprint(\"No need to click accept cookie button\")\n",
        "\t\t# load beautifulsoup\n",
        "\t\ttry:\n",
        "\t\t\tWebDriverWait(new_driver, 10).until(EC.presence_of_element_located((By.XPATH, '//h2[@class=\"__c-heading __c-heading--h2 __u-mb--none\"]')))\n",
        "\t\t\thtml = new_driver.page_source\n",
        "\t\t\tsoup = BeautifulSoup(html,\"html.parser\")\n",
        "\t\t\tnew_driver.close()\n",
        "\t\t\tnew_driver.quit()\n",
        "\t\t\tlist_item = [[item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[0].text.replace(\"\\n\",'').strip().replace(\"  \",\" \"),\n",
        "\t\t\t\t\t\t\t\titem.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip().replace(\"  \",\" \"),\n",
        "\t\t\t\t\t\t\t\titem.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip(),\n",
        "\t\t\t\t\t\t\t\titem.find('div', class_='__c-shipment__reference-content').text.split('  ')[1],\n",
        "\t\t\t\t\t\t\t\titem.find('span', class_='__u-hide--small-medium').text\n",
        "\t\t\t\t\t\t\t\t]\n",
        "\t\t\t\t\t\tif item.find('span', class_='__u-hide--small-medium') != None\n",
        "\t\t\t\t\t\telse [item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[0].text.replace(\"\\n\",'').strip().replace(\"  \",\" \"),\n",
        "\t\t\t\t\t\t\titem.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip().replace(\"  \",\" \"),\n",
        "\t\t\t\t\t\t\titem.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip(),\n",
        "\t\t\t\t\t\t\titem.find('div', class_='__c-shipment__reference-content').text.split('  ')[1],\n",
        "\t\t\t\t\t\t\t\" \"\n",
        "\t\t\t\t\t\t\t]\n",
        "\t\t\t\t\t\tfor item in\\\n",
        "\t\t\t\t\t\tlist(filter(lambda item: item.find('div',class_='__c-shipment-status-tnt__summary').text.replace(\"\\n\",'').strip() != \"Delivered\"\n",
        "\t\t\t\t\t\tand any([item.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace(\"\\n\",'').strip() in deliver_country,\n",
        "\t\t\t\t\t\t\t\t\titem.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace('\\n','').strip().find(\",\") != -1 and\n",
        "\t\t\t\t\t\t\t\t\titem.find_all('div',class_='__c-heading __c-heading--h4 __c-heading--bold __u-mb--none')[1].text.replace('\\n','').strip().split(',')[1].strip() in deliver_country]),\n",
        "\t\t\t\t\t\t\tsoup.find_all('div',class_='__c-shipment')))\n",
        "\t\t\t\t\t\t]\n",
        "\t\t\tlist_pages.remove(cus_ref)\n",
        "\t\t\t[backup.append(i) for i in list_item if i not in backup]\n",
        "\t\texcept TimeoutException:\n",
        "\t\t\tprint(\"Time out, cannot load this page {}\".format(cus_ref+1))\n",
        "\t\t\ttime.sleep(1)\n",
        "\t\t\tnew_driver.close()\n",
        "\t\t\tnew_driver.quit()\n",
        "\t\tprint(\"Size of items list of {}: {}\".format(cus_ref+1,len(list_item)))\n",
        "\t\tprint(\"Timing:{}\".format(datetime.now()\t- start))\n",
        "\tif (datetime.now()-list_time_control[0]).total_seconds() >= 900:\n",
        "\t\tfile_name = \"fedex_data\"\n",
        "\t\tbackup_list = [i for i in backup]\n",
        "\t\tsave_csv(backup_list,file_name)\n",
        "\t\tprint(\"Save csv to drive at {}\".format(datetime.now()))\n",
        "\t\tlist_time_control[0] = datetime.now()\n",
        "\tif (datetime.now() - list_time_control[1]).total_seconds() >= 3600:\n",
        "\t\tfile_name = \"fedex_data_backup\"\n",
        "\t\tbackup_list = [i for i in backup]\n",
        "\t\tsave_csv(backup_list,file_name)\n",
        "\t\tprint(\"Wait 5 minutes to free space...\")\n",
        "\t\ttime.sleep(300)\n",
        "\t\tlist_time_control[1] = datetime.now()\n",
        "\treturn list_item\n",
        "\n",
        "def main(from_page=0, to_page=10000):\n",
        "\tdata = []\n",
        "\tstart = datetime.now()\n",
        "\tsave_time = datetime.now()\n",
        "\tpause_time = datetime.now()\n",
        "\tbackup = mp.Manager().list()\n",
        "\tlist_pages = mp.Manager().list()\n",
        "\tlist_time_control = mp.Manager().list()\n",
        "\tlist_time_control.append(save_time)\n",
        "\tlist_time_control.append(pause_time)\n",
        "\t#print(\"start at {}\".format(start))\n",
        "\tlist_pages.extend(range(from_page,to_page))\n",
        "\twhile len(list_pages) != 0:\n",
        "\t\tprint(\"start at {}\".format(start))\n",
        "\t\tprint(\"Leftover :{}\".format(len(list_pages)))\n",
        "\t\t[data.append(i) for i in list(itertools.chain.from_iterable(Parallel(n_jobs=2, backend='multiprocessing')(delayed(crawl_data_bs4)(j,{},list_pages,backup,start,list_time_control) \n",
        "\t\t\tfor j in list_pages)))\n",
        "\t\t\tif i not in data]\n",
        "\tprint(\"Finish crawl at {}, after {}\".format(datetime.now(),datetime.now()-start))\n",
        "\tsave_csv(data, \"fedex_data\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  login_petco()\n",
        "\t# parser = argparse.ArgumentParser()\n",
        "\t# parser.add_argument('--from_page', action=\"store\")\n",
        "\t# parser.add_argument('--to_page',action=\"store\")\n",
        "\t# args = parser.parse_args()\n",
        "\t# while(True):\n",
        "\t# \tif args.from_page != None and args.to_page != None:\n",
        "\t# \t\tmain(int(args.from_page),int(args.to_page))\n",
        "\t# \telse:\n",
        "\t# \t\tmain()\n",
        "\t# \tprint(\"Done at {}. Wait 10 minutes before start new\".format(datetime.now()))\n",
        "\t# \ttime.sleep(600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0bcf3fdc85e3>\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    driver = webdriver.Chrome('chromedriver',options=options)\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ve_nI1xGq1H",
        "outputId": "ce723f09-20be-4a34-e231-a9630adec431"
      },
      "source": [
        "import argparse\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import selenium.common.exceptions as exception\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import threading\n",
        "import itertools\n",
        "import concurrent\n",
        "from joblib import Parallel, delayed, parallel_backend\n",
        "from queue import Queue\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from fake_useragent import UserAgent\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "# chrome driver\n",
        "def chrome_driver():\n",
        "  options = webdriver.ChromeOptions()\n",
        "  options.add_argument('--ignore-certificate-errors')\n",
        "  # options.add_argument('--headless')\n",
        "  options.add_argument('--no-sandbox')\n",
        "  options.add_argument('--disable-dev-shm-usage')\n",
        "  options.add_argument('--incognito')\n",
        "  options.add_argument(\"--disable-gpu\")\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)\n",
        "  driver.maximize_window\n",
        "  return driver\n",
        "\n",
        "def login_game():\n",
        "  driver = chrome_driver()\n",
        "  driver.implicitly_wait(60)\n",
        "  try:\n",
        "    try:\n",
        "      driver.get('http://202.158.245.65/')\n",
        "\t\t\t# driver_dict[cus_ref] = driver\n",
        "      print(\"Loading: http://202.158.245.65/\")\n",
        "    except exception.WebDriverException:\n",
        "      print(\"Time out, cannot load this page\")\n",
        "      driver.close()\n",
        "      driver.quit()\n",
        "      return list_item\n",
        "  except exception.InvalidSessionIdException:\n",
        "    print(\"cannot load this page\")\n",
        "    driver.close()\n",
        "    driver.quit()\n",
        "    return list_item\n",
        "  try:\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//input[@id=\"imeDispatcherInput\"]')))\n",
        "  except TimeoutException:\n",
        "    print(\"Time out, cannot load this page \")\n",
        "    time.sleep(1)\n",
        "    driver.close()\n",
        "    driver.quit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "pF3riuRqO0rB",
        "outputId": "e6e7def9-93af-4830-fb34-4da637fa94b3"
      },
      "source": [
        "login_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1e2b6c7ee4a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogin_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-192e4d8f1c68>\u001b[0m in \u001b[0;36mlogin_game\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogin_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchrome_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-192e4d8f1c68>\u001b[0m in \u001b[0;36mchrome_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--incognito'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--disable-gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chromedriver'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     keep_alive=keep_alive),\n\u001b[0;32m---> 81\u001b[0;31m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[1;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[1;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sessionId'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: Chrome failed to start: exited abnormally.\n  (unknown error: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /usr/bin/chromium-browser is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n"
          ]
        }
      ]
    }
  ]
}